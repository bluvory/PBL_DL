{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"st_02_2_NeuralNetwork.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"JTj4sXyYD-oa","colab_type":"text"},"source":["# Exercise 2 : Implementing Backpropagation with Python"]},{"cell_type":"code","metadata":{"id":"DX6jIrYqD-og","colab_type":"code","colab":{}},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMIWxO0BD-o7","colab_type":"code","colab":{}},"source":["class NeuralNetwork:\n","    def __init__(self, layers, alpha=0.1):\n","\n","        self.W = []\n","        self.layers = layers\n","        self.alpha = alpha\n","\n","        # start looping from the index of the first layer but\n","        # stop before we reach the last two layers\n","        for i in np.arange(0, len(layers) - 2):\n","            w = np.random.randn(layers[i] + 1, layers[i + 1] + 1)\n","            self.W.append(w / np.sqrt(layers[i]))\n","\n","        w = np.random.randn(layers[-2] + 1, layers[-1])\n","        self.W.append(w / np.sqrt(layers[-2]))\n","\n","    def __repr__(self):\n","        return \"NeuralNetwork: {}\".format(\n","            \"-\".join(str(l) for l in self.layers))\n","\n","    def sigmoid(self, x):\n","        return 1.0 / (1 + np.exp(-x))\n","\n","    def sigmoid_deriv(self, x):\n","        return x * (1 - x)\n","\n","    def fit(self, X, y, epochs=1000, displayUpdate=100):\n","        X = np.c_[X, np.ones((X.shape[0]))]\n","\n","        for epoch in np.arange(0, epochs):\n","            for (x, target) in zip(X, y):\n","                self.fit_partial(x, target)\n","\n","            if epoch == 0 or (epoch + 1) % displayUpdate == 0:\n","                loss = self.calculate_loss(X, y)\n","                print(\"[INFO] epoch={}, loss={:.7f}\".format(\n","                    epoch + 1, loss))\n","\n","    def fit_partial(self, x, y):\n","        A = [np.atleast_2d(x)]\n","\n","        # FEEDFORWARD:\n","        # loop over the layers in the network\n","        for layer in np.arange(0, len(self.W)):\n","            net = A[layer].dot(self.W[layer])\n","\n","            out = self.sigmoid(net)\n","\n","            A.append(out)\n","\n","        # BACKPROPAGATION\n","        error = A[-1] - y\n","\n","        D = [error * self.sigmoid_deriv(A[-1])]\n","\n","        for layer in np.arange(len(A) - 2, 0, -1):\n","            delta = D[-1].dot(self.W[layer].T)\n","            delta = delta * self.sigmoid_deriv(A[layer])\n","            D.append(delta)\n","\n","        D = D[::-1]\n","\n","        # WEIGHT UPDATE PHASE\n","        # loop over the layers\n","        for layer in np.arange(0, len(self.W)):\n","            self.W[layer] += -self.alpha * A[layer].T.dot(D[layer])\n","\n","    def predict(self, X, addBias=True):\n","        p = np.atleast_2d(X)\n","\n","        # check to see if the bias column should be added\n","        if addBias:\n","            p = np.c_[p, np.ones((p.shape[0]))]\n","\n","        # loop over our layers in the network\n","        for layer in np.arange(0, len(self.W)):\n","            p = self.sigmoid(np.dot(p, self.W[layer]))\n","\n","        return p\n","\n","    def calculate_loss(self, X, targets):\n","        targets = np.atleast_2d(targets)\n","        predictions = self.predict(X, addBias=False)\n","        loss = 0.5 * np.sum((predictions - targets) ** 2)\n","\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-EBHVxKjD-pI","colab_type":"text"},"source":["### Neural Network XOR"]},{"cell_type":"code","metadata":{"id":"WhIVvAEcD-pL","colab_type":"code","colab":{}},"source":["X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([[0], [1], [1], [0]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rg4d0sbD-pc","colab_type":"code","colab":{}},"source":["nn = NeuralNetwork([2, 2, 1], alpha=0.5)    # xy값, 노드두개(노드한개면 퍼셉트론), output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_FrMoYuD-pu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593571050978,"user_tz":-540,"elapsed":1044,"user":{"displayName":"루피","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gil8El9Pu__MuDmc6hxhfcNHrr1o4Eew4n5lWTW=s64","userId":"07873363664554410537"}},"outputId":"db4f65de-f58d-4ba1-855f-2cb8c9d8720e"},"source":["print(nn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NeuralNetwork: 2-2-1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GdRvGvqBD-p5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"ok","timestamp":1593571054388,"user_tz":-540,"elapsed":4288,"user":{"displayName":"루피","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gil8El9Pu__MuDmc6hxhfcNHrr1o4Eew4n5lWTW=s64","userId":"07873363664554410537"}},"outputId":"de76645d-5611-4e90-8fc8-8fb15ee85650"},"source":["nn.fit(X, y, epochs=20000, displayUpdate=2000)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] epoch=1, loss=0.5174323\n","[INFO] epoch=2000, loss=0.0047366\n","[INFO] epoch=4000, loss=0.0014448\n","[INFO] epoch=6000, loss=0.0008290\n","[INFO] epoch=8000, loss=0.0005761\n","[INFO] epoch=10000, loss=0.0004396\n","[INFO] epoch=12000, loss=0.0003545\n","[INFO] epoch=14000, loss=0.0002966\n","[INFO] epoch=16000, loss=0.0002546\n","[INFO] epoch=18000, loss=0.0002229\n","[INFO] epoch=20000, loss=0.0001981\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3JFp9FhTD-qG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1593571054391,"user_tz":-540,"elapsed":4110,"user":{"displayName":"루피","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gil8El9Pu__MuDmc6hxhfcNHrr1o4Eew4n5lWTW=s64","userId":"07873363664554410537"}},"outputId":"e0c25486-493f-4513-e9b9-864432bfe662"},"source":["for (x, target) in zip(X, y):\n","    pred = nn.predict(x)[0][0]\n","    step = 1 if pred > 0.5 else 0\n","    print(\"[INFO] data={}, ground-truth={}, pred={:.4f}, step={}\".format(\n","                        x, target[0], pred, step))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] data=[0 0], ground-truth=0, pred=0.0087, step=0\n","[INFO] data=[0 1], ground-truth=1, pred=0.9902, step=1\n","[INFO] data=[1 0], ground-truth=1, pred=0.9902, step=1\n","[INFO] data=[1 1], ground-truth=0, pred=0.0113, step=0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZtHqc_VuD-qY","colab_type":"text"},"source":["### Neural Network MNIST"]},{"cell_type":"code","metadata":{"id":"KeemM30HD-qb","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn import datasets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6CzHW71TD-ql","colab_type":"text"},"source":["pixel intensity values to the range [0, 1]\n","\n","each image is represented by an 8 x 8 = 64-dim feature vector"]},{"cell_type":"code","metadata":{"id":"gdd1Pc2KD-qn","colab_type":"code","colab":{}},"source":["digits = datasets.load_digits()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"gRuItOrBD-qz","colab_type":"code","colab":{}},"source":["digits.images[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bpJvNvn-D-rB","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2er25Tl0D-rS","colab_type":"code","colab":{}},"source":["plt.imshow(digits.images[100])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"biWd7AqrD-rg","colab_type":"code","colab":{}},"source":["digits.target[100]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSn2JUmjD-ro","colab_type":"text"},"source":["construct the training and testing splits"]},{"cell_type":"code","metadata":{"id":"HTXOYDGgD-rp","colab_type":"code","colab":{}},"source":["data = digits.data.astype(\"float\")\n","data = (data - data.min()) / (data.max() - data.min())\n","print(\"[INFO] samples: {}, dim: {}\".format(data.shape[0], data.shape[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JJLW5DYQD-rw","colab_type":"code","colab":{}},"source":["(trainX, testX, trainY, testY) = train_test_split(data,\n","    digits.target, test_size=0.25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EU1TlfuKD-r1","colab_type":"code","colab":{}},"source":["trainY[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-VVJ3Te0D-r5","colab_type":"text"},"source":["convert the labels from integers to vectors"]},{"cell_type":"code","metadata":{"id":"xCYgFTvuD-r6","colab_type":"code","colab":{}},"source":["trainY = LabelBinarizer().fit_transform(trainY)\n","testY = LabelBinarizer().fit_transform(testY)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0O9VxrrD-r_","colab_type":"code","colab":{}},"source":["trainY[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"diNuVFcZD-sD","colab_type":"text"},"source":["train the network"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"sJSgPDJ6D-sD","colab_type":"code","colab":{}},"source":["nn = NeuralNetwork([trainX.shape[1], 32, 16, 10])\n","print(\"[INFO] {}\".format(nn))\n","nn.fit(trainX, trainY, epochs=1000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K1Wb1sJZD-sH","colab_type":"text"},"source":["evaluate the network"]},{"cell_type":"code","metadata":{"id":"L9U54vXBD-sH","colab_type":"code","colab":{}},"source":["predictions = nn.predict(testX)\n","predictions = predictions.argmax(axis=1)\n","print(classification_report(testY.argmax(axis=1), predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvEsqXcmD-sK","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}